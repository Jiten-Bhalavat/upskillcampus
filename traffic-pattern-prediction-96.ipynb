{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-05T11:08:43.731217Z","iopub.execute_input":"2023-08-05T11:08:43.731987Z","iopub.status.idle":"2023-08-05T11:08:43.787383Z","shell.execute_reply.started":"2023-08-05T11:08:43.731943Z","shell.execute_reply":"2023-08-05T11:08:43.785858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing required libraries \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom datetime import datetime\nimport time\nimport seaborn as sns\n\nfrom sklearn.preprocessing import *\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\nimport lightgbm as lgb\nimport xgboost as xgb\n\n# Boosting Algorithm Libraries :\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:10:25.207992Z","iopub.execute_input":"2023-08-05T11:10:25.208534Z","iopub.status.idle":"2023-08-05T11:10:28.476714Z","shell.execute_reply.started":"2023-08-05T11:10:25.208497Z","shell.execute_reply":"2023-08-05T11:10:28.475046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/smart-city-traffic-patterns/test_BdBKkAj.csv')\ntrain = pd.read_csv('/kaggle/input/smart-city-traffic-patterns/train_aWnotuB.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:15:06.811560Z","iopub.execute_input":"2023-08-05T11:15:06.812023Z","iopub.status.idle":"2023-08-05T11:15:06.878088Z","shell.execute_reply.started":"2023-08-05T11:15:06.811987Z","shell.execute_reply":"2023-08-05T11:15:06.876803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data information in train dataframe","metadata":{}},{"cell_type":"code","source":"def data_inf(data,name):\n    print('rows: ',data.shape[0],' ,columns: ',data.shape[1],' in',name,'\\n')\n    data.info()\n    print('\\n')\ndata_inf(train,'Train')\ndisplay(train.head(5).append(train.tail(5)))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:15:08.915251Z","iopub.execute_input":"2023-08-05T11:15:08.915950Z","iopub.status.idle":"2023-08-05T11:15:09.176884Z","shell.execute_reply.started":"2023-08-05T11:15:08.915889Z","shell.execute_reply":"2023-08-05T11:15:09.175498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data information in test dataframe","metadata":{}},{"cell_type":"code","source":"data_inf(test,\"Test\")\ndisplay(test.head(5).append(test.tail(5)))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:15:13.890679Z","iopub.execute_input":"2023-08-05T11:15:13.891148Z","iopub.status.idle":"2023-08-05T11:15:13.918896Z","shell.execute_reply.started":"2023-08-05T11:15:13.891111Z","shell.execute_reply":"2023-08-05T11:15:13.917159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data description","metadata":{}},{"cell_type":"code","source":"display(train.describe())\ndisplay(train.describe(include = 'object'))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:15:52.000546Z","iopub.execute_input":"2023-08-05T11:15:52.001100Z","iopub.status.idle":"2023-08-05T11:15:52.075119Z","shell.execute_reply.started":"2023-08-05T11:15:52.001058Z","shell.execute_reply":"2023-08-05T11:15:52.073536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## drop duplicate rows in train data","metadata":{}},{"cell_type":"code","source":"print('before dropping ',train.shape[0])\ntrain.drop_duplicates(keep=\"first\", inplace=True) \nprint('after dropping ',train.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:16:38.363701Z","iopub.execute_input":"2023-08-05T11:16:38.364371Z","iopub.status.idle":"2023-08-05T11:16:38.392889Z","shell.execute_reply.started":"2023-08-05T11:16:38.364321Z","shell.execute_reply":"2023-08-05T11:16:38.390945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## check for missing values and fill them if there","metadata":{}},{"cell_type":"code","source":"if(train.isnull().sum().sum()==0):\n    print('no missing values in train')\nelse:\n    train.fillna(method='ffill',inplace=True)\nif(test.isnull().sum().sum()==0):\n    print('no missing values in test')    \nelse:\n    test.fillna(method='ffill',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:19:44.347715Z","iopub.execute_input":"2023-08-05T11:19:44.348324Z","iopub.status.idle":"2023-08-05T11:19:44.385034Z","shell.execute_reply.started":"2023-08-05T11:19:44.348278Z","shell.execute_reply":"2023-08-05T11:19:44.383333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting datetime column into datetime ","metadata":{}},{"cell_type":"code","source":"print('before converting :',train['DateTime'].dtype)\ntrain['DateTime'] = pd.to_datetime(train['DateTime'])\ntest['DateTime'] = pd.to_datetime(test['DateTime'])\nprint('after converting :',train['DateTime'].dtype)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:22:30.649889Z","iopub.execute_input":"2023-08-05T11:22:30.650454Z","iopub.status.idle":"2023-08-05T11:22:30.685169Z","shell.execute_reply.started":"2023-08-05T11:22:30.650415Z","shell.execute_reply":"2023-08-05T11:22:30.683553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:22:42.784016Z","iopub.execute_input":"2023-08-05T11:22:42.784530Z","iopub.status.idle":"2023-08-05T11:22:42.803496Z","shell.execute_reply.started":"2023-08-05T11:22:42.784491Z","shell.execute_reply":"2023-08-05T11:22:42.801877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Feature Engineering</h2>\n<h3>Extracting important features from datetime column</h3>","metadata":{}},{"cell_type":"code","source":"# Exploring more features  \ntrain[\"Year\"]= train['DateTime'].dt.year  \ntrain[\"Month\"]= train['DateTime'].dt.month  \ntrain[\"Date_no\"]= train['DateTime'].dt.day  \ntrain[\"Hour\"]= train['DateTime'].dt.hour  \ntrain[\"Day\"]= train.DateTime.dt.strftime(\"%A\")\n\ntest[\"Year\"]= test['DateTime'].dt.year  \ntest[\"Month\"]= test['DateTime'].dt.month  \ntest[\"Date_no\"]= test['DateTime'].dt.day  \ntest[\"Hour\"]= test['DateTime'].dt.hour  \ntest[\"Day\"]= test.DateTime.dt.strftime(\"%A\")","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:23:22.046500Z","iopub.execute_input":"2023-08-05T11:23:22.047001Z","iopub.status.idle":"2023-08-05T11:23:22.522951Z","shell.execute_reply.started":"2023-08-05T11:23:22.046966Z","shell.execute_reply":"2023-08-05T11:23:22.521399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:23:31.122282Z","iopub.execute_input":"2023-08-05T11:23:31.122817Z","iopub.status.idle":"2023-08-05T11:23:31.140408Z","shell.execute_reply.started":"2023-08-05T11:23:31.122775Z","shell.execute_reply":"2023-08-05T11:23:31.139167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:23:37.435032Z","iopub.execute_input":"2023-08-05T11:23:37.436057Z","iopub.status.idle":"2023-08-05T11:23:37.455990Z","shell.execute_reply.started":"2023-08-05T11:23:37.436005Z","shell.execute_reply":"2023-08-05T11:23:37.454799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization ","metadata":{}},{"cell_type":"code","source":"# time series plot\ncolors = [ \"#FFD4DB\",\"#BBE7FE\",\"#D3B5E5\",\"#dfe2b6\"]\nplt.figure(figsize=(20,4),facecolor=\"#627D78\")  \ntime_series=sns.lineplot(x=train['DateTime'],y=\"Vehicles\",data=train, hue=\"Junction\", palette=colors)  \ntime_series.set_title(\"DateTime vs Vehicle\")  \ntime_series.set_ylabel(\"Vehicles in Number\")  \ntime_series.set_xlabel(\"DateTime\") ","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:24:46.890151Z","iopub.execute_input":"2023-08-05T11:24:46.890676Z","iopub.status.idle":"2023-08-05T11:24:48.220318Z","shell.execute_reply.started":"2023-08-05T11:24:46.890638Z","shell.execute_reply":"2023-08-05T11:24:48.218719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#years of traffic at junction\nplt.figure(figsize=(12,5),facecolor=\"#627D78\")  \ncolors = [ \"#FFD4DB\",\"#BBE7FE\",\"#D3B5E5\",\"#dfe2b6\"]\ncount = sns.countplot(data=train, x =train[\"Year\"], hue=\"Junction\", palette=colors)  \ncount.set_title(\"Years of Traffic at Junctions\")  \ncount.set_ylabel(\"Vehicles in numbers\")  \ncount.set_xlabel(\"Date\") ","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:25:15.309144Z","iopub.execute_input":"2023-08-05T11:25:15.310234Z","iopub.status.idle":"2023-08-05T11:25:15.770512Z","shell.execute_reply.started":"2023-08-05T11:25:15.310163Z","shell.execute_reply":"2023-08-05T11:25:15.768835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#heat map\ncorrmat = train.corr()  \nplt.subplots(figsize=(10,10),facecolor=\"#627D78\")  \nsns.heatmap(corrmat,cmap= \"Pastel2\",annot=True,square=True, )  ","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:25:39.074336Z","iopub.execute_input":"2023-08-05T11:25:39.075060Z","iopub.status.idle":"2023-08-05T11:25:39.661096Z","shell.execute_reply.started":"2023-08-05T11:25:39.075008Z","shell.execute_reply":"2023-08-05T11:25:39.659413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## split the train data","metadata":{}},{"cell_type":"code","source":"def datetounix1(df):\n    # Initialising unixtime list\n    unixtime = []\n    \n    # Running a loop for converting Date to seconds\n    for date in df['DateTime']:\n        unixtime.append(time.mktime(date.timetuple()))\n    \n    # Replacing Date with unixtime list\n    df['DateTime'] = unixtime\n    return(df)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:27:31.723424Z","iopub.execute_input":"2023-08-05T11:27:31.724026Z","iopub.status.idle":"2023-08-05T11:27:31.731668Z","shell.execute_reply.started":"2023-08-05T11:27:31.723982Z","shell.execute_reply":"2023-08-05T11:27:31.730469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:28:16.846202Z","iopub.execute_input":"2023-08-05T11:28:16.847715Z","iopub.status.idle":"2023-08-05T11:28:16.871558Z","shell.execute_reply.started":"2023-08-05T11:28:16.847658Z","shell.execute_reply":"2023-08-05T11:28:16.870014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = datetounix1(train.drop(['Vehicles'], axis=1))\ntest_features = datetounix1(test)\n\n\n# Store Features / Predictors in array :\nX = train_features  \nX_valid = test_features\n\n# One Hot Encoding - Using Dummies :\nX = pd.get_dummies(X)\nX_valid = pd.get_dummies(X_valid)\n\n# Store target 'Vehicles' in y array :\ny = train['Vehicles'].to_frame()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=512)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:29:02.516699Z","iopub.execute_input":"2023-08-05T11:29:02.517220Z","iopub.status.idle":"2023-08-05T11:29:03.109206Z","shell.execute_reply.started":"2023-08-05T11:29:02.517175Z","shell.execute_reply":"2023-08-05T11:29:03.107794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBM Regression","metadata":{}},{"cell_type":"code","source":"# Convert the dataset to LightGBM data format\ntrain_data = lgb.Dataset(X_train, label=y_train)\n\n# Set the parameters for the LightGBM regression model\nparams = {\n    'objective': 'regression',\n    'metric': 'rmse'  # Root Mean Squared Error\n}\n\n# Train the LightGBM regression model\nmodel = lgb.train(params,train_data, num_boost_round=100)\n\n# Make predictions on the testing set\ny_pred = model.predict(X_test)\n\n# Evaluating the model\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Printing the evaluation metrics\nprint(\"Mean Squared Error:\", mse)\nprint(\"Mean Absolute Error:\", mae)\nprint(\"R2 Score:\", r2)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:29:30.634538Z","iopub.execute_input":"2023-08-05T11:29:30.635000Z","iopub.status.idle":"2023-08-05T11:29:31.889737Z","shell.execute_reply.started":"2023-08-05T11:29:30.634967Z","shell.execute_reply":"2023-08-05T11:29:31.888026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest regressor","metadata":{}},{"cell_type":"code","source":"# Create a Random Forest regressor\nrf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n\n# Train the model\nrf_regressor.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = rf_regressor.predict(X_test)\n#for i in range(15880):\n#    print(y_pred[i],y_test.iloc[i])","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:30:58.649821Z","iopub.execute_input":"2023-08-05T11:30:58.650380Z","iopub.status.idle":"2023-08-05T11:31:12.961147Z","shell.execute_reply.started":"2023-08-05T11:30:58.650339Z","shell.execute_reply":"2023-08-05T11:31:12.960161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the model\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Printing the evaluation metrics\nprint(\"Mean Squared Error:\", mse)\nprint(\"Mean Absolute Error:\", mae)\nprint(\"R2 Score:\", r2)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T11:31:18.441174Z","iopub.execute_input":"2023-08-05T11:31:18.442360Z","iopub.status.idle":"2023-08-05T11:31:18.457672Z","shell.execute_reply.started":"2023-08-05T11:31:18.442316Z","shell.execute_reply":"2023-08-05T11:31:18.455943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}